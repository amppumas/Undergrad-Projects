{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File correctly processed\n"
     ]
    }
   ],
   "source": [
    "# TODO : Quitar los signos de puntuación del corpus.\n",
    "# TODO : Obtener el stem de cada token en el corpus.\n",
    "# TODO : Obtener el número de tokens y tipos del corpus\n",
    "# TODO : Obtener la gráfica de la distribución de las palabras (curva de Zipf) ordenadas de mayor a menor por sus rangos estadísticos.\n",
    "# TODO : Obtener la gráfica de la curva de Zipf en escala logarítmica.\n",
    "\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "from unicodedata import category\n",
    "from sys import maxunicode\n",
    "from os import walk\n",
    "from nltk.probability import FreqDist\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "# Save all Spanish characters for punctuation in a list\n",
    "punctuation = [char for char in range(maxunicode) if category(chr(char)).startswith('P')]\n",
    "\n",
    "class Corpus():\n",
    "    def __init__(self,directory_path,encoding):\n",
    "        self.directory_path = directory_path\n",
    "        self.encoding = encoding\n",
    "        self.text = ''\n",
    "        self.tokens = None\n",
    "        self.types = None\n",
    "        self.stems = dict()\n",
    "        self.graph = None\n",
    "        self.loggraph = None\n",
    "        self.processFile()\n",
    "    def processFile(self):\n",
    "        self.retrieve_text()\n",
    "        no_punctuation = self.text.translate(dict.fromkeys(punctuation))\n",
    "        self.tokens = word_tokenize(no_punctuation.lower())\n",
    "        stemmer = SnowballStemmer(\"spanish\")\n",
    "        for token in self.tokens:\n",
    "            self.stems.update({token:stemmer.stem(token)})\n",
    "        self.obtain_graph()\n",
    "        print(\"File correctly processed\")\n",
    "\n",
    "    def retrieve_text(self):\n",
    "        filenames = self.files_from_directory()\n",
    "        for filename in filenames:\n",
    "            with open(self.directory_path+'/'+filename, encoding=self.encoding) as currentfile:\n",
    "                for line in currentfile:\n",
    "                    self.text+=line\n",
    "\n",
    "    def files_from_directory(self):\n",
    "        f = []\n",
    "        for (dirpath, dirnames, filenames) in walk(self.directory_path):\n",
    "            f.extend(filenames)\n",
    "            break\n",
    "        return f\n",
    "\n",
    "    def obtain_graph(self):\n",
    "        dist = FreqDist(word for word in self.tokens)\n",
    "        words_tuple = dist.most_common()\n",
    "        self.types = [word[0] for word in words_tuple]\n",
    "        y = [word[1] for word in words_tuple]\n",
    "        self.graph = [go.Scatter(\n",
    "                x=self.types,\n",
    "                y=y,\n",
    "                name='Frequency of words',\n",
    "                line=dict(\n",
    "                    color=('rgb(205, 12, 24)'),\n",
    "                    width=4)\n",
    "                )]\n",
    "        self.loggraph = go.Figure(\n",
    "            data =\n",
    "                [go.Scatter(\n",
    "                x=self.types,\n",
    "                y=y,\n",
    "                name='Frequency of words in Logaritmic Scale',\n",
    "                line=dict(\n",
    "                    color=('rgb(205, 12, 24)'),\n",
    "                    width=4)\n",
    "                )],\n",
    "            layout = go.Layout(\n",
    "                yaxis=dict(\n",
    "                type='log',\n",
    "                autorange=True)\n",
    "                )\n",
    "        )\n",
    "\n",
    "    def numTokens(self):\n",
    "        return 'The corpus has '+str(len(self.tokens))+' tokens'\n",
    "\n",
    "    def numTypes(self):\n",
    "        return 'The corpus has '+str(len(self.types))+' types'\n",
    "\n",
    "    def plotGraph(self):\n",
    "        py.iplot(self.graph,filename=\"zipf\")\n",
    "\n",
    "    def plotLogGraph(self):\n",
    "        py.iplot(self.loggraph,filename=\"logzipf\")\n",
    "\n",
    "corpus = Corpus(\"corpus1\",'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus.plotGraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-22-2e4456f4bd19>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-22-2e4456f4bd19>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    py.iplot(,filename=\"zipf\")\u001b[0m\n\u001b[1;37m             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "py.iplot(,filename=\"zipf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
